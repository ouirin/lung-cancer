{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer:  DESKTOP-F8TV69I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import settings\n",
    "import helpers\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas\n",
    "import ntpath\n",
    "import cv2\n",
    "import numpy\n",
    "from typing import List, Tuple\n",
    "from keras.optimizers import Adam, SGD , RMSprop , Adagrad , Adadelta , Adam , Adamax , Nadam\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, UpSampling2D, merge, Convolution3D, MaxPooling3D, UpSampling3D, LeakyReLU, BatchNormalization, Flatten, Dense, Dropout, ZeroPadding3D, AveragePooling3D, Activation\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.metrics import binary_accuracy, binary_crossentropy, mean_squared_error, mean_absolute_error\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Add\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import multiply\n",
    "\n",
    "from keras.layers.core import Permute\n",
    "\n",
    "from keras.layers.core import Reshape\n",
    "\n",
    "from keras.layers import GRU,Reshape\n",
    "\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "\n",
    "from keras.utils.vis_utils  import plot_model\n",
    "\n",
    "# limit memory usage..\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.50\n",
    "#set_session(tf.Session(config=config))\n",
    "\n",
    "# zonder aug, 10:1 99 train, 97 test, 0.27 cross entropy, before commit 573\n",
    "# 3 pools istead of 4 gives (bigger end layer) gives much worse validation accuray + logloss .. strange ?\n",
    "# 32 x 32 x 32 lijkt het beter te doen dan 48 x 48 x 48..\n",
    "\n",
    "K.set_image_dim_ordering(\"tf\")\n",
    "CUBE_SIZE = 32\n",
    "MEAN_PIXEL_VALUE = settings.MEAN_PIXEL_VALUE_NODULE\n",
    "POS_WEIGHT = 2\n",
    "NEGS_PER_POS = 20\n",
    "P_TH = 0.6\n",
    "# POS_IMG_DIR = \"luna16_train_cubes_pos\"\n",
    "LEARN_RATE = 0.001\n",
    "\n",
    "USE_DROPOUT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初次训练\n",
    "\n",
    "使用全部luna16数据\n",
    "\n",
    "训练数据：edge，candidate=0，positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train/holdout files.\n",
      "Pos samples:  1186\n",
      "Edge samples:  177585\n",
      "Luna samples:  421156\n",
      "Falsepos LUNA count:  7057\n",
      "Positive Train Count: 948\n",
      "Negative Train Count: 500163\n",
      "Train count:  525172 , holdout count:  125737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n",
      "d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 525172.0, 10, validation_steps=125737.0, callbacks=[<keras.ca..., validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                  Output Shape                   Param #         Connected to                                   \n",
      "============================================================================================================================================\n",
      "input_10 (InputLayer)                         (None, 8, 8, 8, 32)            0                                                              \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistributed)          (None, 8, 2048)                1045776         input_10[0][0]                                 \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "gru_10 (GRU)                                  (None, 8, 512)                 3933696         time_distributed_6[0][0]                       \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "permute_9 (Permute)                           (None, 512, 8)                 0               gru_10[0][0]                                   \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "dense_11 (Dense)                              (None, 512, 8)                 72              permute_9[0][0]                                \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "attention_vec (Permute)                       (None, 8, 512)                 0               dense_11[0][0]                                 \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "attention_mul (Multiply)                      (None, 8, 512)                 0               gru_10[0][0]                                   \n",
      "                                                                                             attention_vec[0][0]                            \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)                           (None, 4096)                   0               attention_mul[0][0]                            \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "dense_12 (Dense)                              (None, 512)                    2097664         flatten_9[0][0]                                \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "out_class (Dense)                             (None, 1)                      513             dense_12[0][0]                                 \n",
      "============================================================================================================================================\n",
      "Total params: 7,077,721\n",
      "Trainable params: 7,077,721\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "learnrate:  0.001  epoch:  0\n",
      " 62499/525172 [==>...........................] - ETA: 11:49:57 - loss: 0.1338 - binary_accuracy: 0.9643 - binary_crossentropy: 0.1338- ETA: 11:50:19 - loss: 0.1340 -  - ETA: 11:50:14 -  - ETA: 11:49:59 - loss: 0.1338 - binary_accuracy: 0.9643 - binary_crossentropy - ETA: 11:49:58 - loss: 0.1338 - binary_accuracy: 0.9643 - binary_crossentroMean:  81.72985370205689\n",
      "124999/525172 [======>.......................] - ETA: 10:10:32 - loss: 0.1045 - binary_accuracy: 0.9714 - binary_crossentropy: 0.1045- ETA: 10:11:30 - loss: 0 - ETA: 10:11:24 - loss: 0.1047 - binary_accuMean:  81.76281157156372\n",
      "187499/525172 [=========>....................] - ETA: 8:34:26 - loss: 0.0895 - binary_accuracy: 0.9750 - binary_crossentropy: 0.0895Mean:  81.7438610157369\n",
      "249999/525172 [=============>................] - ETA: 6:59:52 - loss: 0.0797 - binary_accuracy: 0.9774 - binary_crossentropy: 0.0797Mean:  81.74649563917542\n",
      "312499/525172 [================>.............] - ETA: 5:25:04 - loss: 0.0724 - binary_accuracy: 0.9791 - binary_crossentropy: 0.0724Mean:  81.75089505084838\n",
      "374999/525172 [====================>.........] - ETA: 3:50:10 - loss: 0.0665 - binary_accuracy: 0.9805 - binary_crossentropy: 0.0665 ETA: 3:50:12 - loss: 0.0665 - binary_accuracy: 0.98Mean:  81.75678555008952\n",
      "437499/525172 [=======================>......] - ETA: 2:14:59 - loss: 0.0616 - binary_accuracy: 0.9818 - binary_crossentropy: 0.0616Mean:  81.75549094317627\n",
      "476431/525172 [==========================>...] - ETA: 1:18:05 - loss: 0.0588 - binary_accuracy: 0.9825 - binary_crossentropy: 0.0588"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if True:\n",
    "            \n",
    "        train(model_name=\"luna16_full_RNN\", train_full_set=False, load_weights_path=None)      \n",
    "        \n",
    "        if not os.path.exists(\"models/\"):\n",
    "            os.mkdir(\"models\")\n",
    "            \n",
    "        shutil.copy(\"workdir/model_luna16_full_RNN_best.hd5\", \"models/model_luna16_full_RNN_best.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, train_full_set, load_weights_path):\n",
    "    \n",
    "    batch_size = 16\n",
    "    \n",
    "    #获得训练和测试集合，以：路径、class label，size label的形式保存\n",
    "    train_files, holdout_files = get_train_holdout_files(train_percentage=80, full_luna_set=train_full_set)\n",
    "    \n",
    "    #训练数据集\n",
    "    train_gen = data_generator(batch_size, train_files, train_set=True)\n",
    "    \n",
    "    #print(train_gen.__next__()[1])\n",
    "    #sys.exit(1)\n",
    "    \n",
    "    #测试数据集\n",
    "    holdout_gen = data_generator(batch_size, holdout_files, train_set=False)\n",
    "   \n",
    "    #动态设置学习率\n",
    "    learnrate_scheduler = LearningRateScheduler(step_decay)\n",
    "    \n",
    "    #获取model\n",
    "    model = get_net(load_weight_path=load_weights_path)\n",
    "    \n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\"workdir/model_\" + model_name + \"_\"  + \"_e\" + \"{epoch:02d}-{val_loss:.4f}.hd5\", monitor='val_loss', verbose=1, save_best_only=not train_full_set, save_weights_only=False, mode='auto', period=1)\n",
    "   \n",
    "    checkpoint_fixed_name = ModelCheckpoint(\"workdir/model_\" + model_name + \"_\"  + \"_best.hd5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    \n",
    "    model.fit_generator(train_gen, len(train_files) / 1, 10, validation_data=holdout_gen, nb_val_samples=len(holdout_files) / 1, callbacks=[checkpoint, checkpoint_fixed_name, learnrate_scheduler])\n",
    " \n",
    "    model.save(\"workdir/model_\" + model_name + \"_\"  + \"_end.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    \n",
    "    res = 0.001\n",
    " \n",
    "    if epoch > 5:\n",
    "        res = 0.0001\n",
    "        \n",
    "    print(\"learnrate: \", res, \" epoch: \", epoch)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(input_shape=(CUBE_SIZE, CUBE_SIZE, CUBE_SIZE, 1), load_weight_path=None) -> Model:\n",
    "        \n",
    "    input_shapeT1=(8,32)  \n",
    "    input1 = Input( shape=input_shapeT1 ) \n",
    "    gru1 = GRU(128,activation='tanh', recurrent_activation='sigmoid',return_sequences=True)(input1)\n",
    "    gru1 = attention_3d_block(gru1)\n",
    "    gru1 = Flatten()(gru1)\n",
    "    Encoder1 = Model(input1, gru1)\n",
    "\n",
    "    input_shapeT2=(8,8,32)\n",
    "    input2 = Input( shape=input_shapeT2 )\n",
    "    embed2 = TimeDistributed(Encoder1)(input2)\n",
    "    gru2 = GRU(256,activation='tanh', recurrent_activation='sigmoid',return_sequences=True)(embed2)\n",
    "    gru2 = attention_3d_block(gru2)\n",
    "    gru2 = Flatten()(gru2)\n",
    "    Encoder2 = Model(input2, gru2)\n",
    "    \n",
    "\n",
    "    input_shapeT3=(8,8,8,32) \n",
    "    input3 = Input( shape=input_shapeT3 )\n",
    "    embed3 = TimeDistributed(Encoder2)(input3)\n",
    "    gru3 = GRU(512,activation='tanh', recurrent_activation='sigmoid',return_sequences=True)(embed3)\n",
    "    gru3 = attention_3d_block(gru3)\n",
    "    gru3 = Flatten()(gru3)\n",
    "   \n",
    "    \n",
    "    gru3 = Dense(512, activation='relu')(gru3)\n",
    "    \n",
    "    out_class = Dense(1, activation='sigmoid', name='out_class')(gru3)\n",
    "    model = Model(input=input3, output=out_class)\n",
    "  \n",
    "    \n",
    "    if load_weight_path is not None:\n",
    "        model.load_weights(load_weight_path, by_name=False)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=LEARN_RATE, beta_1=0.9, beta_2=0.9, epsilon=1e-08, amsgrad=True), loss={\"out_class\": \"binary_crossentropy\"}, metrics={\"out_class\": [binary_accuracy, binary_crossentropy] })\n",
    "    model.summary(line_length=140)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                  Output Shape                   Param #         Connected to                                   \n",
      "============================================================================================================================================\n",
      "input_4 (InputLayer)                          (None, 8, 8, 8, 32)            0                                                              \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistributed)          (None, 8, 2048)                1045776         input_4[0][0]                                  \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "gru_4 (GRU)                                   (None, 8, 512)                 3933696         time_distributed_2[0][0]                       \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "permute_3 (Permute)                           (None, 512, 8)                 0               gru_4[0][0]                                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "dense_3 (Dense)                               (None, 512, 8)                 72              permute_3[0][0]                                \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "attention_vec (Permute)                       (None, 8, 512)                 0               dense_3[0][0]                                  \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "attention_mul (Multiply)                      (None, 8, 512)                 0               gru_4[0][0]                                    \n",
      "                                                                                             attention_vec[0][0]                            \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)                           (None, 4096)                   0               attention_mul[0][0]                            \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "dense_4 (Dense)                               (None, 512)                    2097664         flatten_3[0][0]                                \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "out_class (Dense)                             (None, 1)                      513             dense_4[0][0]                                  \n",
      "============================================================================================================================================\n",
      "Total params: 7,077,721\n",
      "Trainable params: 7,077,721\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1dde6928d30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "    #input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(8, activation='softmax')(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    #output_attention_mul = merge([inputs, a_probs], name=’attention_mul’, mode=’mul’)\n",
    "    output_attention_mul = multiply([inputs, a_probs], name='attention_mul')\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, record_list, train_set):\n",
    "    \n",
    "    batch_idx = 0\n",
    "    means = []\n",
    "    random_state = numpy.random.RandomState(1301)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        img_list = []\n",
    "        class_list = []\n",
    "        size_list = []\n",
    "        \n",
    "        if train_set:\n",
    "            random.shuffle(record_list)\n",
    "            \n",
    "        CROP_SIZE = CUBE_SIZE\n",
    "        \n",
    "        #逐一遍历所有数据\n",
    "        for record_idx, record_item in enumerate(record_list):\n",
    "            \n",
    "            class_label = record_item[1]\n",
    "            size_label = record_item[2]              #直径不管你训练不训练，它都是一个已知的数据，所以保留\n",
    "            \n",
    "            #处理negative cube\n",
    "            if class_label == 0:\n",
    "                \n",
    "                cube_image = helpers.load_cube_img(record_item[0], 6, 8, 48)\n",
    "              \n",
    "                wiggle = 48 - CROP_SIZE - 1\n",
    "                indent_x = 0\n",
    "                indent_y = 0\n",
    "                indent_z = 0\n",
    "                \n",
    "                if wiggle > 0:\n",
    "                    indent_x = random.randint(0, wiggle)\n",
    "                    indent_y = random.randint(0, wiggle)\n",
    "                    indent_z = random.randint(0, wiggle)\n",
    "                \n",
    "                #截取到crop_size大小的cube\n",
    "                cube_image = cube_image[indent_z:indent_z + CROP_SIZE, indent_y:indent_y + CROP_SIZE, indent_x:indent_x + CROP_SIZE]\n",
    "                \n",
    "                #数据增强\n",
    "                if train_set:   \n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = numpy.fliplr(cube_image)\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = numpy.flipud(cube_image)\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = cube_image[:, :, ::-1]\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = cube_image[:, ::-1, :]\n",
    "\n",
    "                if CROP_SIZE != CUBE_SIZE:\n",
    "                    \n",
    "                    cube_image = helpers.rescale_patient_images2(cube_image, (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE))\n",
    "                    \n",
    "                assert cube_image.shape == (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE)\n",
    "                \n",
    "            #处理positive cube\n",
    "            else:\n",
    "                cube_image = helpers.load_cube_img(record_item[0], 8, 8, 64)\n",
    "\n",
    "                if train_set:\n",
    "                    pass\n",
    "\n",
    "                current_cube_size = cube_image.shape[0]\n",
    "                \n",
    "                indent_x = (current_cube_size - CROP_SIZE) / 2\n",
    "                indent_y = (current_cube_size - CROP_SIZE) / 2\n",
    "                indent_z = (current_cube_size - CROP_SIZE) / 2\n",
    "                \n",
    "                #数据增强\n",
    "                wiggle_indent = CROP_SIZE / 4\n",
    "                wiggle = current_cube_size - CROP_SIZE - CROP_SIZE / 2 - 1\n",
    "                    \n",
    "                if train_set:\n",
    "                    \n",
    "                    indent_x = wiggle_indent + random.randint(0, wiggle)\n",
    "                    indent_y = wiggle_indent + random.randint(0, wiggle)\n",
    "                    indent_z = wiggle_indent + random.randint(0, wiggle)\n",
    "\n",
    "                indent_x = int(indent_x)\n",
    "                indent_y = int(indent_y)\n",
    "                indent_z = int(indent_z)\n",
    "                \n",
    "                #截取到crop_size大小的cube\n",
    "                cube_image = cube_image[indent_z:indent_z + CROP_SIZE, indent_y:indent_y + CROP_SIZE, indent_x:indent_x + CROP_SIZE]\n",
    "                \n",
    "                if CROP_SIZE != CUBE_SIZE:\n",
    "                    cube_image = helpers.rescale_patient_images2(cube_image, (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE))\n",
    "                    \n",
    "                assert cube_image.shape == (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE)\n",
    "                \n",
    "                #数据增强\n",
    "                if train_set:\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = numpy.fliplr(cube_image)\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = numpy.flipud(cube_image)\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = cube_image[:, :, ::-1]\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = cube_image[:, ::-1, :]\n",
    "                        \n",
    "                        \n",
    "            #查看cube的均值，每100万个cube看一次\n",
    "            means.append(cube_image.mean())\n",
    "            if train_set: \n",
    "                if len(means) % 1000000 == 0:\n",
    "                    print(\"Mean: \", sum(means) / len(means))\n",
    "            \n",
    "            \n",
    "            #RNN输入数据的正规化 1024*32 \n",
    "            img3d = prepare_image_for_net3D_RNN(cube_image)\n",
    "                    \n",
    "            #添加数据\n",
    "            img_list.append(img3d)\n",
    "            class_list.append(class_label)\n",
    "            size_list.append(size_label)\n",
    "\n",
    "            batch_idx += 1\n",
    "            \n",
    "            if batch_idx >= batch_size:\n",
    "                \n",
    "                x = numpy.vstack(img_list)\n",
    "                y_class = numpy.vstack(class_list)\n",
    "                y_size = numpy.vstack(size_list)\n",
    "                yield x, {\"out_class\": y_class, \"out_malignancy\": y_size}\n",
    "                img_list = []\n",
    "                class_list = []\n",
    "                size_list = []\n",
    "                batch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_for_net3D_RNN(img):\n",
    "    \n",
    "    img = img\n",
    "    img = img.astype(numpy.float32)\n",
    "    img -= MEAN_PIXEL_VALUE\n",
    "    img /= 255.\n",
    "    \n",
    "    imgN=numpy.zeros(shape=(16,32,32))\n",
    "\n",
    "    for i in range(16):\n",
    "    \n",
    "        imgN[i]=(img[2*i]+img[2*i+1])/2\n",
    "        \n",
    "        \n",
    "    imgN = imgN.reshape(1,8,8,8,32)\n",
    "    \n",
    "    return imgN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_holdout_files(train_percentage=80, full_luna_set=False):\n",
    "    \n",
    "    print(\"Get train/holdout files.\")\n",
    "    \n",
    "    \n",
    "    ####################################################################################################\n",
    "    ####################################################################################################\n",
    "    \n",
    "    #positive cube的整理\n",
    "    \n",
    "    #luna16 阳性集合1\n",
    "    pos_samples = glob.glob(settings.BASE_DIR_SSD + \"generated_traindata/luna16_train_cubes_lidc/*.png\")\n",
    "    print(\"Pos samples: \", len(pos_samples))\n",
    "    \n",
    "    random.shuffle(pos_samples)\n",
    "      \n",
    "    #分割训练数据和测试数据\n",
    "    train_pos_count = int((len(pos_samples) * train_percentage) / 100)\n",
    "    pos_samples_train = pos_samples[:train_pos_count]\n",
    "    pos_samples_holdout = pos_samples[train_pos_count:]\n",
    "    \n",
    "    #如果需要训练所有数据，训练集则为全集\n",
    "    if full_luna_set:\n",
    "        pos_samples_train += pos_samples_holdout\n",
    "       \n",
    "\n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    #negative cube的整理\n",
    "    \n",
    "    neg_samples_edge = glob.glob(settings.BASE_DIR_SSD + \"generated_traindata/luna16_train_cubes_auto/*_edge.png\")\n",
    "    print(\"Edge samples: \", len(neg_samples_edge))\n",
    "    \n",
    "    neg_samples_luna = glob.glob(settings.BASE_DIR_SSD + \"generated_traindata/luna16_train_cubes_auto/*_luna.png\")\n",
    "    print(\"Luna samples: \", len(neg_samples_luna))\n",
    "    \n",
    "    neg_samples_falsepos = glob.glob(settings.BASE_DIR_SSD + \"generated_traindata/luna16_train_cubes_auto/*_falsepos.png\")\n",
    "    print(\"Falsepos LUNA count: \", len(neg_samples_falsepos))\n",
    "    \n",
    "    neg_samples = neg_samples_edge + neg_samples_luna\n",
    "    random.shuffle(neg_samples)\n",
    "    \n",
    "    #分割训练数据和测试数据\n",
    "    train_neg_count = int((len(neg_samples) * train_percentage) / 100)\n",
    "    neg_samples_train = neg_samples[:train_neg_count]\n",
    "    neg_samples_train += neg_samples_falsepos + neg_samples_falsepos + neg_samples_falsepos \n",
    "    neg_samples_holdout = neg_samples[train_neg_count:]\n",
    "    \n",
    "    #如果需要训练所有数据，训练集则为全集\n",
    "    if full_luna_set:\n",
    "        neg_samples_train += neg_samples_holdout\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    print(\"Positive Train Count:\",len(pos_samples_train))\n",
    "    print(\"Negative Train Count:\",len(neg_samples_train))\n",
    "\n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    \n",
    "    #建立描述集合\n",
    "    train_res = []\n",
    "    holdout_res = []\n",
    "    sets = [(train_res, pos_samples_train, neg_samples_train), (holdout_res, pos_samples_holdout, neg_samples_holdout)]\n",
    "    \n",
    "    #对集合进行处理\n",
    "    for set_item in sets:\n",
    "        \n",
    "        pos_idx = 0\n",
    "        negs_per_pos = NEGS_PER_POS\n",
    "        \n",
    "        res = set_item[0]\n",
    "        pos_samples = set_item[1]\n",
    "        neg_samples = set_item[2]\n",
    "        \n",
    "        for index, neg_sample_path in enumerate(neg_samples):\n",
    "            \n",
    "            res.append((neg_sample_path, 0, 0))\n",
    "            \n",
    "            if index % negs_per_pos == 0:\n",
    "                \n",
    "                pos_sample_path = pos_samples[pos_idx]\n",
    "                \n",
    "                file_name = ntpath.basename(pos_sample_path)\n",
    "                \n",
    "                parts = file_name.split(\"_\")\n",
    "                \n",
    "                if True:\n",
    "                    \n",
    "                    class_label = int(parts[-2])\n",
    "                    size_label = int(parts[-3])\n",
    "                    \n",
    "                    assert class_label == 1\n",
    "                    assert parts[-1] == \"pos.png\"\n",
    "                    assert size_label >= 1\n",
    "                    \n",
    "                    \n",
    "                res.append((pos_sample_path, class_label, size_label))\n",
    "                pos_idx += 1\n",
    "                pos_idx %= len(pos_samples)\n",
    "                \n",
    "    print(\"Train count: \", len(train_res), \", holdout count: \", len(holdout_res))\n",
    "    \n",
    "    return train_res, holdout_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

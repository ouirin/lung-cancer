{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import settings\n",
    "import helpers\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas\n",
    "import ntpath\n",
    "import cv2\n",
    "import numpy\n",
    "from typing import List, Tuple\n",
    "from keras.optimizers import Adam, SGD , RMSprop , Adagrad , Adadelta , Adam , Adamax , Nadam\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, UpSampling2D, merge, Convolution3D, MaxPooling3D, UpSampling3D, LeakyReLU, BatchNormalization, Flatten, Dense, Dropout, ZeroPadding3D, AveragePooling3D, Activation\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.metrics import binary_accuracy, binary_crossentropy, mean_squared_error, mean_absolute_error\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Add\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import multiply\n",
    "\n",
    "from keras.layers.core import Permute\n",
    "\n",
    "from keras.layers.core import Reshape\n",
    "\n",
    "from keras.layers import GRU,Reshape\n",
    "\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "\n",
    "from keras.utils.vis_utils  import plot_model\n",
    "\n",
    "# limit memory usage..\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.50\n",
    "#set_session(tf.Session(config=config))\n",
    "\n",
    "# zonder aug, 10:1 99 train, 97 test, 0.27 cross entropy, before commit 573\n",
    "# 3 pools istead of 4 gives (bigger end layer) gives much worse validation accuray + logloss .. strange ?\n",
    "# 32 x 32 x 32 lijkt het beter te doen dan 48 x 48 x 48..\n",
    "\n",
    "K.set_image_dim_ordering(\"tf\")\n",
    "CUBE_SIZE = 32\n",
    "MEAN_PIXEL_VALUE = settings.MEAN_PIXEL_VALUE_NODULE\n",
    "POS_WEIGHT = 2\n",
    "NEGS_PER_POS = 20\n",
    "P_TH = 0.6\n",
    "# POS_IMG_DIR = \"luna16_train_cubes_pos\"\n",
    "LEARN_RATE = 0.001\n",
    "\n",
    "USE_DROPOUT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train/holdout files.\n",
      "Pos samples:  1186\n",
      "Edge samples:  177585\n",
      "Luna samples:  421156\n",
      "Falsepos LUNA count:  7057\n",
      "Positive Train Count: 1186\n",
      "Negative Train Count: 619912\n",
      "Train count:  650908 , holdout count:  125737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `AveragePooling3D` call to the Keras 2 API: `AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), padding=\"same\")`\n",
      "  \"\"\"\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", name=\"conv1\", strides=(1, 1, 1), padding=\"same\")`\n",
      "  \n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "  import sys\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", name=\"conv2\", strides=(1, 1, 1), padding=\"same\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3a\", strides=(1, 1, 1), padding=\"same\")`\n",
      "  app.launch_new_instance()\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3b\", strides=(1, 1, 1), padding=\"same\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4a\", strides=(1, 1, 1), padding=\"same\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4b\", strides=(1, 1, 1), padding=\"same\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (2, 2, 2), activation=\"relu\", name=\"last_64\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(1, (1, 1, 1), activation=\"sigmoid\", name=\"out_class_last\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                   Output Shape                                            Param #              \n",
      "============================================================================================================================================\n",
      "input_1 (InputLayer)                                           (None, 32, 32, 32, 1)                                   0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "average_pooling3d_2 (AveragePooling3D)                         (None, 16, 32, 32, 1)                                   0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv1 (Conv3D)                                                 (None, 16, 32, 32, 64)                                  1792                 \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "pool1 (MaxPooling3D)                                           (None, 16, 16, 16, 64)                                  0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv2 (Conv3D)                                                 (None, 16, 16, 16, 128)                                 221312               \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "pool2 (MaxPooling3D)                                           (None, 8, 8, 8, 128)                                    0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv3a (Conv3D)                                                (None, 8, 8, 8, 256)                                    884992               \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv3b (Conv3D)                                                (None, 8, 8, 8, 256)                                    1769728              \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "pool3 (MaxPooling3D)                                           (None, 4, 4, 4, 256)                                    0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv4a (Conv3D)                                                (None, 4, 4, 4, 512)                                    3539456              \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv4b (Conv3D)                                                (None, 4, 4, 4, 512)                                    7078400              \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "pool4 (MaxPooling3D)                                           (None, 2, 2, 2, 512)                                    0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "last_64 (Conv3D)                                               (None, 1, 1, 1, 64)                                     262208               \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "out_class_last (Conv3D)                                        (None, 1, 1, 1, 1)                                      65                   \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "out_class (Flatten)                                            (None, 1)                                               0                    \n",
      "============================================================================================================================================\n",
      "Total params: 13,757,953\n",
      "Trainable params: 13,757,953\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 650908.0, 10, validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=125737.0)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "learnrate:  0.001  epoch:  0\n",
      "   910/650908 [..............................] - ETA: 27:06:25 - loss: 0.2089 - binary_accuracy: 0.9530 - binary_crossentropy: 0.2089"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-468f64bd63c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"luna16_full_CNN\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_full_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_weights_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"models/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a2f0f3e2ed57>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model_name, train_full_set, load_weights_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mcheckpoint_fixed_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"workdir/model_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m\"_best.hd5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mholdout_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholdout_files\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_fixed_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearnrate_scheduler\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"workdir/model_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m\"_end.hd5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if True:\n",
    "            \n",
    "        train(model_name=\"luna16_full_CNN\", train_full_set=True, load_weights_path=None)      \n",
    "        \n",
    "        if not os.path.exists(\"models/\"):\n",
    "            os.mkdir(\"models\")\n",
    "            \n",
    "        shutil.copy(\"workdir/model_luna16_full_CNN_best.hd5\", \"models/model_luna16_full_CNN_best.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, train_full_set, load_weights_path):\n",
    "    \n",
    "    batch_size = 16\n",
    "    \n",
    "    #获得训练和测试集合，以：路径、class label，size label的形式保存\n",
    "    train_files, holdout_files = get_train_holdout_files(train_percentage=80, full_luna_set=train_full_set)\n",
    "    \n",
    "    #训练数据集\n",
    "    train_gen = data_generator(batch_size, train_files, train_set=True)\n",
    "    \n",
    "    #print(train_gen.__next__()[1])\n",
    "    #sys.exit(1)\n",
    "    \n",
    "    #测试数据集\n",
    "    holdout_gen = data_generator(batch_size, holdout_files, train_set=False)\n",
    "   \n",
    "    #动态设置学习率\n",
    "    learnrate_scheduler = LearningRateScheduler(step_decay)\n",
    "    \n",
    "    #获取model\n",
    "    model = get_net(load_weight_path=load_weights_path)\n",
    "    \n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\"workdir/model_\" + model_name + \"_\"  + \"_e\" + \"{epoch:02d}-{val_loss:.4f}.hd5\", monitor='val_loss', verbose=1, save_best_only=not train_full_set, save_weights_only=False, mode='auto', period=1)\n",
    "   \n",
    "    checkpoint_fixed_name = ModelCheckpoint(\"workdir/model_\" + model_name + \"_\"  + \"_best.hd5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    \n",
    "    model.fit_generator(train_gen, len(train_files) / 1, 10, validation_data=holdout_gen, nb_val_samples=len(holdout_files) / 1, callbacks=[checkpoint, checkpoint_fixed_name, learnrate_scheduler])\n",
    " \n",
    "    model.save(\"workdir/model_\" + model_name + \"_\"  + \"_end.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    res = 0.001\n",
    "    if epoch > 5:\n",
    "        res = 0.0001\n",
    "    print(\"learnrate: \", res, \" epoch: \", epoch)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(input_shape=(CUBE_SIZE, CUBE_SIZE, CUBE_SIZE, 1), load_weight_path=None) -> Model:  #期待返回类型为model\n",
    "    \n",
    "    inputs = Input(shape=input_shape, name=\"input_1\")\n",
    "    x = inputs\n",
    "    x = AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode=\"same\")(x)\n",
    "    x = Convolution3D(64, 3, 3, 3, activation='relu', border_mode='same', name='conv1', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1')(x)\n",
    "\n",
    "    # 2nd layer group\n",
    "    x = Convolution3D(128, 3, 3, 3, activation='relu', border_mode='same', name='conv2', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2')(x)\n",
    "    if USE_DROPOUT:\n",
    "        x = Dropout(p=0.3)(x)\n",
    "\n",
    "    # 3rd layer group\n",
    "    x = Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3b', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3')(x)\n",
    "    if USE_DROPOUT:\n",
    "        x = Dropout(p=0.4)(x)\n",
    "\n",
    "    # 4th layer group\n",
    "    x = Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4b', subsample=(1, 1, 1),)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4')(x)\n",
    "    if USE_DROPOUT:\n",
    "        x = Dropout(p=0.5)(x)\n",
    "\n",
    "    #输出1\n",
    "    last64 = Convolution3D(64, 2, 2, 2, activation=\"relu\", name=\"last_64\")(x)\n",
    "    out_class = Convolution3D(1, 1, 1, 1, activation=\"sigmoid\", name=\"out_class_last\")(last64)\n",
    "    out_class = Flatten(name=\"out_class\")(out_class)\n",
    "    \n",
    "    #输出2\n",
    "    #out_malignancy = Convolution3D(1, 1, 1, 1, activation=None, name=\"out_malignancy_last\")(last64)\n",
    "    #out_malignancy = Flatten(name=\"out_malignancy\")(out_malignancy)\n",
    "\n",
    "    model = Model(input=inputs, output=out_class)\n",
    "    \n",
    "    if load_weight_path is not None:\n",
    "        model.load_weights(load_weight_path, by_name=False)\n",
    "    \n",
    "    #编译模型\n",
    "    model.compile(optimizer=SGD(lr=LEARN_RATE, momentum=0.9, nesterov=True), loss={ \"out_class\": \"binary_crossentropy\" }, metrics={\"out_class\": [binary_accuracy, binary_crossentropy] } )\n",
    "    model.summary(line_length=140)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `AveragePooling3D` call to the Keras 2 API: `AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), padding=\"same\")`\n",
      "  \"\"\"\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", name=\"conv1\", strides=(1, 1, 1), padding=\"same\")`\n",
      "  \n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "  import sys\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", name=\"conv2\", strides=(1, 1, 1), padding=\"same\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3a\", strides=(1, 1, 1), padding=\"same\")`\n",
      "  app.launch_new_instance()\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3b\", strides=(1, 1, 1), padding=\"same\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4a\", strides=(1, 1, 1), padding=\"same\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4b\", strides=(1, 1, 1), padding=\"same\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (2, 2, 2), activation=\"relu\", name=\"last_64\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(1, (1, 1, 1), activation=\"sigmoid\", name=\"out_class_last\")`\n",
      "d:\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                   Output Shape                                            Param #              \n",
      "============================================================================================================================================\n",
      "input_1 (InputLayer)                                           (None, 32, 32, 32, 1)                                   0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "average_pooling3d_1 (AveragePooling3D)                         (None, 16, 32, 32, 1)                                   0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv1 (Conv3D)                                                 (None, 16, 32, 32, 64)                                  1792                 \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "pool1 (MaxPooling3D)                                           (None, 16, 16, 16, 64)                                  0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv2 (Conv3D)                                                 (None, 16, 16, 16, 128)                                 221312               \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "pool2 (MaxPooling3D)                                           (None, 8, 8, 8, 128)                                    0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv3a (Conv3D)                                                (None, 8, 8, 8, 256)                                    884992               \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv3b (Conv3D)                                                (None, 8, 8, 8, 256)                                    1769728              \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "pool3 (MaxPooling3D)                                           (None, 4, 4, 4, 256)                                    0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv4a (Conv3D)                                                (None, 4, 4, 4, 512)                                    3539456              \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "conv4b (Conv3D)                                                (None, 4, 4, 4, 512)                                    7078400              \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "pool4 (MaxPooling3D)                                           (None, 2, 2, 2, 512)                                    0                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "last_64 (Conv3D)                                               (None, 1, 1, 1, 64)                                     262208               \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "out_class_last (Conv3D)                                        (None, 1, 1, 1, 1)                                      65                   \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "out_class (Flatten)                                            (None, 1)                                               0                    \n",
      "============================================================================================================================================\n",
      "Total params: 13,757,953\n",
      "Trainable params: 13,757,953\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x289855c7828>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, record_list, train_set):\n",
    "    \n",
    "    batch_idx = 0\n",
    "    means = []\n",
    "    random_state = numpy.random.RandomState(1301)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        img_list = []\n",
    "        class_list = []\n",
    "        size_list = []\n",
    "        \n",
    "        if train_set:\n",
    "            random.shuffle(record_list)\n",
    "            \n",
    "        CROP_SIZE = CUBE_SIZE\n",
    "        \n",
    "        #逐一遍历所有数据\n",
    "        for record_idx, record_item in enumerate(record_list):\n",
    "            \n",
    "            class_label = record_item[1]\n",
    "            size_label = record_item[2]              #直径不管你训练不训练，它都是一个已知的数据，所以保留\n",
    "            \n",
    "            #处理negative cube\n",
    "            if class_label == 0:\n",
    "                \n",
    "                cube_image = helpers.load_cube_img(record_item[0], 6, 8, 48)\n",
    "              \n",
    "                wiggle = 48 - CROP_SIZE - 1\n",
    "                indent_x = 0\n",
    "                indent_y = 0\n",
    "                indent_z = 0\n",
    "                \n",
    "                if wiggle > 0:\n",
    "                    indent_x = random.randint(0, wiggle)\n",
    "                    indent_y = random.randint(0, wiggle)\n",
    "                    indent_z = random.randint(0, wiggle)\n",
    "                \n",
    "                #截取到crop_size大小的cube\n",
    "                cube_image = cube_image[indent_z:indent_z + CROP_SIZE, indent_y:indent_y + CROP_SIZE, indent_x:indent_x + CROP_SIZE]\n",
    "                \n",
    "                #数据增强\n",
    "                if train_set:   \n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = numpy.fliplr(cube_image)\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = numpy.flipud(cube_image)\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = cube_image[:, :, ::-1]\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = cube_image[:, ::-1, :]\n",
    "\n",
    "                if CROP_SIZE != CUBE_SIZE:\n",
    "                    \n",
    "                    cube_image = helpers.rescale_patient_images2(cube_image, (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE))\n",
    "                    \n",
    "                assert cube_image.shape == (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE)\n",
    "                \n",
    "            #处理positive cube\n",
    "            else:\n",
    "                cube_image = helpers.load_cube_img(record_item[0], 8, 8, 64)\n",
    "\n",
    "                if train_set:\n",
    "                    pass\n",
    "\n",
    "                current_cube_size = cube_image.shape[0]\n",
    "                \n",
    "                indent_x = (current_cube_size - CROP_SIZE) / 2\n",
    "                indent_y = (current_cube_size - CROP_SIZE) / 2\n",
    "                indent_z = (current_cube_size - CROP_SIZE) / 2\n",
    "                \n",
    "                #数据增强\n",
    "                wiggle_indent = CROP_SIZE / 4\n",
    "                wiggle = current_cube_size - CROP_SIZE - CROP_SIZE / 2 - 1\n",
    "                    \n",
    "                if train_set:\n",
    "                    \n",
    "                    indent_x = wiggle_indent + random.randint(0, wiggle)\n",
    "                    indent_y = wiggle_indent + random.randint(0, wiggle)\n",
    "                    indent_z = wiggle_indent + random.randint(0, wiggle)\n",
    "\n",
    "                indent_x = int(indent_x)\n",
    "                indent_y = int(indent_y)\n",
    "                indent_z = int(indent_z)\n",
    "                \n",
    "                #截取到crop_size大小的cube\n",
    "                cube_image = cube_image[indent_z:indent_z + CROP_SIZE, indent_y:indent_y + CROP_SIZE, indent_x:indent_x + CROP_SIZE]\n",
    "                \n",
    "                if CROP_SIZE != CUBE_SIZE:\n",
    "                    cube_image = helpers.rescale_patient_images2(cube_image, (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE))\n",
    "                    \n",
    "                assert cube_image.shape == (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE)\n",
    "                \n",
    "                #数据增强\n",
    "                if train_set:\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = numpy.fliplr(cube_image)\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = numpy.flipud(cube_image)\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = cube_image[:, :, ::-1]\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        cube_image = cube_image[:, ::-1, :]\n",
    "                        \n",
    "                        \n",
    "            #查看cube的均值，每100万个cube看一次\n",
    "            means.append(cube_image.mean())\n",
    "            if train_set: \n",
    "                if len(means) % 1000000 == 0:\n",
    "                    print(\"Mean: \", sum(means) / len(means))\n",
    "            \n",
    "            \n",
    "            #3D卷积的正规化 32*32*32\n",
    "            img3d = prepare_image_for_net3D(cube_image)\n",
    "                    \n",
    "            #添加数据\n",
    "            img_list.append(img3d)\n",
    "            class_list.append(class_label)\n",
    "            size_list.append(size_label)\n",
    "\n",
    "            batch_idx += 1\n",
    "            \n",
    "            if batch_idx >= batch_size:\n",
    "                \n",
    "                x = numpy.vstack(img_list)\n",
    "                y_class = numpy.vstack(class_list)\n",
    "                y_size = numpy.vstack(size_list)\n",
    "                yield x, {\"out_class\": y_class, \"out_malignancy\": y_size}\n",
    "                img_list = []\n",
    "                class_list = []\n",
    "                size_list = []\n",
    "                batch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_for_net3D(img):\n",
    "    img = img.astype(numpy.float32)\n",
    "    img -= MEAN_PIXEL_VALUE\n",
    "    img /= 255.\n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2], 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_holdout_files(train_percentage=80, full_luna_set=False):\n",
    "    \n",
    "    print(\"Get train/holdout files.\")\n",
    "    \n",
    "    ####################################################################################################\n",
    "    ####################################################################################################\n",
    "    \n",
    "    #positive cube的整理\n",
    "    \n",
    "    #luna16 阳性集合1\n",
    "    pos_samples = glob.glob(settings.BASE_DIR_SSD + \"generated_traindata/luna16_train_cubes_lidc/*.png\")\n",
    "    print(\"Pos samples: \", len(pos_samples))\n",
    "    \n",
    "    random.shuffle(pos_samples)\n",
    "      \n",
    "    #分割训练数据和测试数据\n",
    "    train_pos_count = int((len(pos_samples) * train_percentage) / 100)\n",
    "    pos_samples_train = pos_samples[:train_pos_count]\n",
    "    pos_samples_holdout = pos_samples[train_pos_count:]\n",
    "    \n",
    "    #如果需要训练所有数据，训练集则为全集\n",
    "    if full_luna_set:\n",
    "        pos_samples_train += pos_samples_holdout\n",
    "       \n",
    "\n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    #negative cube的整理\n",
    "    \n",
    "    neg_samples_edge = glob.glob(settings.BASE_DIR_SSD + \"generated_traindata/luna16_train_cubes_auto/*_edge.png\")\n",
    "    print(\"Edge samples: \", len(neg_samples_edge))\n",
    "    \n",
    "    neg_samples_luna = glob.glob(settings.BASE_DIR_SSD + \"generated_traindata/luna16_train_cubes_auto/*_luna.png\")\n",
    "    print(\"Luna samples: \", len(neg_samples_luna))\n",
    "    \n",
    "    neg_samples_falsepos = glob.glob(settings.BASE_DIR_SSD + \"generated_traindata/luna16_train_cubes_auto/*_falsepos.png\")\n",
    "    print(\"Falsepos LUNA count: \", len(neg_samples_falsepos))\n",
    "    \n",
    "    neg_samples = neg_samples_edge + neg_samples_luna\n",
    "    random.shuffle(neg_samples)\n",
    "    \n",
    "    #分割训练数据和测试数据\n",
    "    train_neg_count = int((len(neg_samples) * train_percentage) / 100)\n",
    "    neg_samples_train = neg_samples[:train_neg_count]\n",
    "    neg_samples_train += neg_samples_falsepos + neg_samples_falsepos + neg_samples_falsepos \n",
    "    neg_samples_holdout = neg_samples[train_neg_count:]\n",
    "    \n",
    "    \n",
    "    #如果需要训练所有数据，训练集则为全集\n",
    "    if full_luna_set:\n",
    "        neg_samples_train += neg_samples_holdout\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    print(\"Positive Train Count:\",len(pos_samples_train))\n",
    "    print(\"Negative Train Count:\",len(neg_samples_train))\n",
    "\n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    \n",
    "    #建立描述集合\n",
    "    train_res = []\n",
    "    holdout_res = []\n",
    "    sets = [(train_res, pos_samples_train, neg_samples_train), (holdout_res, pos_samples_holdout, neg_samples_holdout)]\n",
    "    \n",
    "    #对集合进行处理\n",
    "    for set_item in sets:\n",
    "        \n",
    "        pos_idx = 0\n",
    "        negs_per_pos = NEGS_PER_POS\n",
    "        \n",
    "        res = set_item[0]\n",
    "        pos_samples = set_item[1]\n",
    "        neg_samples = set_item[2]\n",
    "        \n",
    "        for index, neg_sample_path in enumerate(neg_samples):\n",
    "            \n",
    "            res.append((neg_sample_path, 0, 0))\n",
    "            \n",
    "            if index % negs_per_pos == 0:\n",
    "                \n",
    "                pos_sample_path = pos_samples[pos_idx]\n",
    "                \n",
    "                file_name = ntpath.basename(pos_sample_path)\n",
    "                \n",
    "                parts = file_name.split(\"_\")\n",
    "                \n",
    "                if True:\n",
    "                    \n",
    "                    class_label = int(parts[-2])\n",
    "                    size_label = int(parts[-3])\n",
    "                    \n",
    "                    assert class_label == 1\n",
    "                    assert parts[-1] == \"pos.png\"\n",
    "                    assert size_label >= 1\n",
    "                    \n",
    "                    \n",
    "                res.append((pos_sample_path, class_label, size_label))\n",
    "                pos_idx += 1\n",
    "                pos_idx %= len(pos_samples)\n",
    "                \n",
    "    print(\"Train count: \", len(train_res), \", holdout count: \", len(holdout_res))\n",
    "    \n",
    "    return train_res, holdout_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

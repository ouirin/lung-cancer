{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer:  DESKTOP-F8TV69I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import settings\n",
    "import helpers\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas\n",
    "import ntpath\n",
    "import cv2\n",
    "import numpy\n",
    "from typing import List, Tuple\n",
    "from keras.optimizers import Adam, SGD , RMSprop , Adagrad , Adadelta , Adam , Adamax , Nadam\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, UpSampling2D, merge, Convolution3D, MaxPooling3D, UpSampling3D, LeakyReLU, BatchNormalization, Flatten, Dense, Dropout, ZeroPadding3D, AveragePooling3D, Activation\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.metrics import binary_accuracy, binary_crossentropy, mean_squared_error, mean_absolute_error\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Add\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import multiply\n",
    "\n",
    "from keras.layers.core import Permute\n",
    "\n",
    "from keras.layers.core import Reshape\n",
    "\n",
    "from keras.layers import GRU,Reshape\n",
    "\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "\n",
    "from keras.utils.vis_utils  import plot_model\n",
    "\n",
    "# limit memory usage..\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.50\n",
    "#set_session(tf.Session(config=config))\n",
    "\n",
    "# zonder aug, 10:1 99 train, 97 test, 0.27 cross entropy, before commit 573\n",
    "# 3 pools istead of 4 gives (bigger end layer) gives much worse validation accuray + logloss .. strange ?\n",
    "# 32 x 32 x 32 lijkt het beter te doen dan 48 x 48 x 48..\n",
    "\n",
    "K.set_image_dim_ordering(\"tf\")\n",
    "CUBE_SIZE = 32\n",
    "MEAN_PIXEL_VALUE = settings.MEAN_PIXEL_VALUE_NODULE\n",
    "POS_WEIGHT = 2\n",
    "NEGS_PER_POS = 20\n",
    "P_TH = 0.6\n",
    "# POS_IMG_DIR = \"luna16_train_cubes_pos\"\n",
    "LEARN_RATE = 0.001\n",
    "\n",
    "USE_DROPOUT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train/holdout files.\n",
      "Samples Quantity:  5741\n",
      "Train Count: 5741\n",
      "Train count:  5741 , holdout count:  1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ou..., inputs=Tensor(\"in...)`\n",
      "d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 5741.0, 10, validation_steps=1149.0, validation_data=<generator..., callbacks=[<keras.ca...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                  Output Shape                   Param #         Connected to                                   \n",
      "============================================================================================================================================\n",
      "input_9 (InputLayer)                          (None, 8, 8, 8, 32)            0                                                              \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistributed)          (None, 8, 2048)                1045776         input_9[0][0]                                  \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "gru_9 (GRU)                                   (None, 8, 512)                 3933696         time_distributed_6[0][0]                       \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "permute_9 (Permute)                           (None, 512, 8)                 0               gru_9[0][0]                                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "dense_11 (Dense)                              (None, 512, 8)                 72              permute_9[0][0]                                \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "attention_vec (Permute)                       (None, 8, 512)                 0               dense_11[0][0]                                 \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "attention_mul (Multiply)                      (None, 8, 512)                 0               gru_9[0][0]                                    \n",
      "                                                                                             attention_vec[0][0]                            \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)                           (None, 4096)                   0               attention_mul[0][0]                            \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "dense_12 (Dense)                              (None, 512)                    2097664         flatten_9[0][0]                                \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "out_sphericiy (Dense)                         (None, 1)                      513             dense_12[0][0]                                 \n",
      "============================================================================================================================================\n",
      "Total params: 7,077,721\n",
      "Trainable params: 7,077,721\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "learnrate:  0.001  epoch:  0\n",
      "5741/5741 [==============================] - 1056s 184ms/step - loss: 0.2425 - mean_absolute_error2: 0.2425 - val_loss: 0.2483 - val_mean_absolute_error2: 0.2483\n",
      "\n",
      "Epoch 00001: saving model to workdir/model_Attribute_Predictor_CNN__e01-0.2483.hd5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24835, saving model to workdir/model_Attribute_Predictor_CNN__best.hd5\n",
      "Epoch 2/10\n",
      "learnrate:  0.001  epoch:  1\n",
      "5741/5741 [==============================] - 1020s 178ms/step - loss: 0.2393 - mean_absolute_error2: 0.2393 - val_loss: 0.2398 - val_mean_absolute_error2: 0.2398\n",
      "\n",
      "Epoch 00002: saving model to workdir/model_Attribute_Predictor_CNN__e02-0.2398.hd5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24835 to 0.23982, saving model to workdir/model_Attribute_Predictor_CNN__best.hd5\n",
      "Epoch 3/10\n",
      "learnrate:  0.001  epoch:  2\n",
      "5741/5741 [==============================] - 1020s 178ms/step - loss: 0.2388 - mean_absolute_error2: 0.2388 - val_loss: 0.2388 - val_mean_absolute_error2: 0.2388\n",
      "\n",
      "Epoch 00003: saving model to workdir/model_Attribute_Predictor_CNN__e03-0.2388.hd5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.23982 to 0.23884, saving model to workdir/model_Attribute_Predictor_CNN__best.hd5\n",
      "Epoch 4/10\n",
      "learnrate:  0.001  epoch:  3\n",
      "5741/5741 [==============================] - 1022s 178ms/step - loss: 0.2381 - mean_absolute_error2: 0.2381 - val_loss: 0.2381 - val_mean_absolute_error2: 0.2381\n",
      "\n",
      "Epoch 00004: saving model to workdir/model_Attribute_Predictor_CNN__e04-0.2381.hd5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23884 to 0.23814, saving model to workdir/model_Attribute_Predictor_CNN__best.hd5\n",
      "Epoch 5/10\n",
      "learnrate:  0.001  epoch:  4\n",
      "5741/5741 [==============================] - 1022s 178ms/step - loss: 0.2374 - mean_absolute_error2: 0.2374 - val_loss: 0.2360 - val_mean_absolute_error2: 0.2360\n",
      "\n",
      "Epoch 00005: saving model to workdir/model_Attribute_Predictor_CNN__e05-0.2360.hd5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23814 to 0.23603, saving model to workdir/model_Attribute_Predictor_CNN__best.hd5\n",
      "Epoch 6/10\n",
      "learnrate:  0.001  epoch:  5\n",
      "5741/5741 [==============================] - 1021s 178ms/step - loss: 0.2368 - mean_absolute_error2: 0.2368 - val_loss: 0.2367 - val_mean_absolute_error2: 0.2367\n",
      "\n",
      "Epoch 00006: saving model to workdir/model_Attribute_Predictor_CNN__e06-0.2367.hd5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23603\n",
      "Epoch 7/10\n",
      "learnrate:  0.0001  epoch:  6\n",
      "5741/5741 [==============================] - 1021s 178ms/step - loss: 0.2354 - mean_absolute_error2: 0.2354 - val_loss: 0.2357 - val_mean_absolute_error2: 0.2357\n",
      "\n",
      "Epoch 00007: saving model to workdir/model_Attribute_Predictor_CNN__e07-0.2357.hd5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.23603 to 0.23568, saving model to workdir/model_Attribute_Predictor_CNN__best.hd5\n",
      "Epoch 8/10\n",
      "learnrate:  0.0001  epoch:  7\n",
      "5741/5741 [==============================] - 1023s 178ms/step - loss: 0.2349 - mean_absolute_error2: 0.2349 - val_loss: 0.2358 - val_mean_absolute_error2: 0.2358\n",
      "\n",
      "Epoch 00008: saving model to workdir/model_Attribute_Predictor_CNN__e08-0.2358.hd5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23568\n",
      "Epoch 9/10\n",
      "learnrate:  0.0001  epoch:  8\n",
      "5741/5741 [==============================] - 1018s 177ms/step - loss: 0.2347 - mean_absolute_error2: 0.2347 - val_loss: 0.2352 - val_mean_absolute_error2: 0.2352\n",
      "\n",
      "Epoch 00009: saving model to workdir/model_Attribute_Predictor_CNN__e09-0.2352.hd5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.23568 to 0.23525, saving model to workdir/model_Attribute_Predictor_CNN__best.hd5\n",
      "Epoch 10/10\n",
      "learnrate:  0.0001  epoch:  9\n",
      "5741/5741 [==============================] - 1017s 177ms/step - loss: 0.2342 - mean_absolute_error2: 0.2342 - val_loss: 0.2346 - val_mean_absolute_error2: 0.2346\n",
      "\n",
      "Epoch 00010: saving model to workdir/model_Attribute_Predictor_CNN__e10-0.2346.hd5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.23525 to 0.23464, saving model to workdir/model_Attribute_Predictor_CNN__best.hd5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'workdir/model_luna16_full_CNN_best.hd5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-cc351b240b87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"models\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"workdir/model_luna16_full_CNN_best.hd5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"models/model_luna16_full_CNN_best.hd5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'workdir/model_luna16_full_CNN_best.hd5'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if True:\n",
    "            \n",
    "        train(model_name=\"Attribute_Predictor_CNN\", train_full_set=True, load_weights_path=None)      \n",
    "        \n",
    "        if not os.path.exists(\"models/\"):\n",
    "            os.mkdir(\"models\")\n",
    "            \n",
    "        shutil.copy(\"workdir/model_luna16_full_CNN_best.hd5\", \"models/model_luna16_full_CNN_best.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, train_full_set, load_weights_path):\n",
    "    \n",
    "    batch_size = 16\n",
    "    \n",
    "    #获得训练和测试集合，以：路径、class label，size label的形式保存\n",
    "    train_files, holdout_files = get_train_holdout_files(train_percentage=80, full_luna_set=train_full_set)\n",
    "    \n",
    "    #训练数据集\n",
    "    train_gen = data_generator(batch_size, train_files, train_set=True)\n",
    "    \n",
    "    #print(train_gen.__next__()[1])\n",
    "    #sys.exit(1)\n",
    "    \n",
    "    #测试数据集\n",
    "    holdout_gen = data_generator(batch_size, holdout_files, train_set=False)\n",
    "   \n",
    "    #动态设置学习率\n",
    "    learnrate_scheduler = LearningRateScheduler(step_decay)\n",
    "    \n",
    "    #获取model\n",
    "    model = get_net(load_weight_path=load_weights_path)\n",
    "    \n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\"workdir/model_\" + model_name + \"_\"  + \"_e\" + \"{epoch:02d}-{val_loss:.4f}.hd5\", monitor='val_loss', verbose=1, save_best_only=not train_full_set, save_weights_only=False, mode='auto', period=1)\n",
    "   \n",
    "    checkpoint_fixed_name = ModelCheckpoint(\"workdir/model_\" + model_name + \"_\"  + \"_best.hd5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    \n",
    "    model.fit_generator(train_gen, len(train_files) / 1, 10, validation_data=holdout_gen, nb_val_samples=len(holdout_files) / 1, callbacks=[checkpoint, checkpoint_fixed_name, learnrate_scheduler])\n",
    " \n",
    "    model.save(\"workdir/model_\" + model_name + \"_\"  + \"_end.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    res = 0.001\n",
    "    if epoch > 5:\n",
    "        res = 0.0001\n",
    "    print(\"learnrate: \", res, \" epoch: \", epoch)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(input_shape=(CUBE_SIZE, CUBE_SIZE, CUBE_SIZE, 1), load_weight_path=None) -> Model:\n",
    "        \n",
    "    input_shapeT1=(8,32)  \n",
    "    input1 = Input( shape=input_shapeT1 ) \n",
    "    gru1 = GRU(128,activation='tanh', recurrent_activation='sigmoid',return_sequences=True)(input1)\n",
    "    gru1 = attention_3d_block(gru1)\n",
    "    gru1 = Flatten()(gru1)\n",
    "    Encoder1 = Model(input1, gru1)\n",
    "\n",
    "    input_shapeT2=(8,8,32)\n",
    "    input2 = Input( shape=input_shapeT2 )\n",
    "    embed2 = TimeDistributed(Encoder1)(input2)\n",
    "    gru2 = GRU(256,activation='tanh', recurrent_activation='sigmoid',return_sequences=True)(embed2)\n",
    "    gru2 = attention_3d_block(gru2)\n",
    "    gru2 = Flatten()(gru2)\n",
    "    Encoder2 = Model(input2, gru2)\n",
    "    \n",
    "\n",
    "    input_shapeT3=(8,8,8,32) \n",
    "    input3 = Input( shape=input_shapeT3 )\n",
    "    embed3 = TimeDistributed(Encoder2)(input3)\n",
    "    gru3 = GRU(512,activation='tanh', recurrent_activation='sigmoid',return_sequences=True)(embed3)\n",
    "    gru3 = attention_3d_block(gru3)\n",
    "    gru3 = Flatten()(gru3)\n",
    "   \n",
    "    \n",
    "    gru3 = Dense(512, activation='relu')(gru3)\n",
    "    \n",
    "    out_sphericiy = Dense(1, activation=None, name='out_sphericiy')(gru3)\n",
    "    model = Model(input=input3, output=out_sphericiy)\n",
    "  \n",
    "    \n",
    "    if load_weight_path is not None:\n",
    "        model.load_weights(load_weight_path, by_name=False)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=LEARN_RATE, beta_1=0.9, beta_2=0.9, epsilon=1e-08, amsgrad=True), loss={\"out_sphericiy\": mean_absolute_error2}, metrics={\"out_sphericiy\": [mean_absolute_error2] })\n",
    "    model.summary(line_length=140)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error2(y_true, y_pred):\n",
    "    return K.mean( K.abs((y_pred-y_true)/y_true),axis=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "   \n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(8, activation='softmax')(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = multiply([inputs, a_probs], name='attention_mul')\n",
    "    \n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                  Output Shape                   Param #         Connected to                                   \n",
      "============================================================================================================================================\n",
      "input_6 (InputLayer)                          (None, 8, 8, 8, 32)            0                                                              \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistributed)          (None, 8, 2048)                1045776         input_6[0][0]                                  \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "gru_6 (GRU)                                   (None, 8, 512)                 3933696         time_distributed_4[0][0]                       \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "permute_6 (Permute)                           (None, 512, 8)                 0               gru_6[0][0]                                    \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "dense_7 (Dense)                               (None, 512, 8)                 72              permute_6[0][0]                                \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "attention_vec (Permute)                       (None, 8, 512)                 0               dense_7[0][0]                                  \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "attention_mul (Multiply)                      (None, 8, 512)                 0               gru_6[0][0]                                    \n",
      "                                                                                             attention_vec[0][0]                            \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)                           (None, 4096)                   0               attention_mul[0][0]                            \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "dense_8 (Dense)                               (None, 512)                    2097664         flatten_6[0][0]                                \n",
      "____________________________________________________________________________________________________________________________________________\n",
      "out_sphericiy (Dense)                         (None, 1)                      513             dense_8[0][0]                                  \n",
      "============================================================================================================================================\n",
      "Total params: 7,077,721\n",
      "Trainable params: 7,077,721\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ou..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x22494f3efd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, record_list, train_set):\n",
    "    \n",
    "    batch_idx = 0\n",
    "    means = []\n",
    "    random_state = numpy.random.RandomState(1301)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        img_list = []\n",
    "        subtlety_list = []\n",
    "        lobulation_list = []\n",
    "        internal_structure_list = []\n",
    "        calcification_list = []\n",
    "        texture_list = []\n",
    "        spiculation_list = []\n",
    "        margin_list = []\n",
    "        sphericiy_list = []\n",
    "        malignacy_list = []\n",
    "        diameter_list = []\n",
    "        \n",
    "        if train_set:\n",
    "            random.shuffle(record_list)\n",
    "            \n",
    "        CROP_SIZE = CUBE_SIZE\n",
    "        \n",
    "        #逐一遍历所有数据\n",
    "        for record_idx, record_item in enumerate(record_list):\n",
    "            \n",
    "            subtlety_label = record_item[10] \n",
    "            lobulation_label = record_item[9] \n",
    "            internal_structure_label = record_item[8] \n",
    "            calcification_label = record_item[7] \n",
    "            texture_label = record_item[6] \n",
    "            spiculation_label = record_item[5] \n",
    "            margin_label = record_item[4] \n",
    "            sphericiy_label = record_item[3] \n",
    "            malignacy_label = record_item[2] \n",
    "            diameter_label = round(record_item[1],4) \n",
    "                         \n",
    "            #处理cube\n",
    "            cube_image = helpers.load_cube_img(record_item[0], 8, 8, 64)\n",
    "\n",
    "            current_cube_size = cube_image.shape[0]\n",
    "\n",
    "            indent_x = (current_cube_size - CROP_SIZE) / 2\n",
    "            indent_y = (current_cube_size - CROP_SIZE) / 2\n",
    "            indent_z = (current_cube_size - CROP_SIZE) / 2\n",
    "\n",
    "            #数据增强\n",
    "            wiggle_indent = CROP_SIZE / 4\n",
    "            wiggle = current_cube_size - CROP_SIZE - CROP_SIZE / 2 - 1\n",
    "\n",
    "            if train_set:\n",
    "\n",
    "                indent_x = wiggle_indent + random.randint(0, wiggle)\n",
    "                indent_y = wiggle_indent + random.randint(0, wiggle)\n",
    "                indent_z = wiggle_indent + random.randint(0, wiggle)\n",
    "\n",
    "            indent_x = int(indent_x)\n",
    "            indent_y = int(indent_y)\n",
    "            indent_z = int(indent_z)\n",
    "\n",
    "            #截取到crop_size大小的cube\n",
    "            cube_image = cube_image[indent_z:indent_z + CROP_SIZE, indent_y:indent_y + CROP_SIZE, indent_x:indent_x + CROP_SIZE]\n",
    "\n",
    "            if CROP_SIZE != CUBE_SIZE:\n",
    "                cube_image = helpers.rescale_patient_images2(cube_image, (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE))\n",
    "\n",
    "            assert cube_image.shape == (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE)\n",
    "\n",
    "            #数据增强\n",
    "            if train_set:\n",
    "                if random.randint(0, 100) > 50:\n",
    "                    cube_image = numpy.fliplr(cube_image)\n",
    "                if random.randint(0, 100) > 50:\n",
    "                    cube_image = numpy.flipud(cube_image)\n",
    "                if random.randint(0, 100) > 50:\n",
    "                    cube_image = cube_image[:, :, ::-1]\n",
    "                if random.randint(0, 100) > 50:\n",
    "                    cube_image = cube_image[:, ::-1, :]\n",
    "            \n",
    "            #3D卷积的正规化 32*32*32\n",
    "            img3d = prepare_image_for_net3D_RNN(cube_image)\n",
    "                    \n",
    "            #添加数据\n",
    "            img_list.append(img3d)\n",
    "            \n",
    "            subtlety_list.append(subtlety_label)\n",
    "            lobulation_list.append(lobulation_label) \n",
    "            internal_structure_list.append(internal_structure_label) \n",
    "            calcification_list.append(calcification_label) \n",
    "            texture_list.append(texture_label)  \n",
    "            spiculation_list.append(spiculation_label)  \n",
    "            margin_list.append(margin_label)  \n",
    "            sphericiy_list.append(sphericiy_label)  \n",
    "            malignacy_list.append(malignacy_label)  \n",
    "            diameter_list.append(diameter_label)  \n",
    "\n",
    "            batch_idx += 1\n",
    "            \n",
    "            if batch_idx >= batch_size:\n",
    "                \n",
    "                x = numpy.vstack(img_list)\n",
    "                y_diamter = numpy.vstack(diameter_list)\n",
    "                y_malignacy = numpy.vstack(malignacy_list)\n",
    "                y_sphericiy = numpy.vstack(sphericiy_list)\n",
    "                y_margin = numpy.vstack(margin_list)\n",
    "                y_spiculation = numpy.vstack(spiculation_list)\n",
    "                y_texture = numpy.vstack(texture_list)\n",
    "                y_calcification = numpy.vstack(calcification_list)\n",
    "                y_internal_structure = numpy.vstack(internal_structure_list)\n",
    "                y_lobulation = numpy.vstack(lobulation_list)\n",
    "                y_subtlety = numpy.vstack(subtlety_list)\n",
    "\n",
    "                yield x, {\"out_diamter\": y_diamter, \"out_malignancy\": y_malignacy, \"out_sphericiy\": y_sphericiy, \"out_margin\": y_margin, \"out_spiculation\": y_spiculation, \"out_texture\": y_texture, \"out_calcification\": y_calcification, \"out_internal_structure\": y_internal_structure, \"out_lobulation\": y_lobulation, \"out_subtlety\": y_subtlety }\n",
    "                img_list = []\n",
    "                subtlety_list = []\n",
    "                lobulation_list = []\n",
    "                internal_structure_list = []\n",
    "                calcification_list = []\n",
    "                texture_list = []\n",
    "                spiculation_list = []\n",
    "                margin_list = []\n",
    "                sphericiy_list = []\n",
    "                malignacy_list = []\n",
    "                diameter_list = []\n",
    "                batch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_for_net3D_RNN(img):\n",
    "    \n",
    "    img = img\n",
    "    img = img.astype(numpy.float32)\n",
    "    img -= MEAN_PIXEL_VALUE\n",
    "    img /= 255.\n",
    "    \n",
    "    imgN=numpy.zeros(shape=(16,32,32))\n",
    "\n",
    "    for i in range(16):\n",
    "    \n",
    "        imgN[i]=(img[2*i]+img[2*i+1])/2\n",
    "        \n",
    "        \n",
    "    imgN = imgN.reshape(1,8,8,8,32)\n",
    "    \n",
    "    return imgN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_holdout_files(train_percentage=80, full_luna_set=False):\n",
    "    \n",
    "    print(\"Get train/holdout files.\")\n",
    "    \n",
    "    ####################################################################################################\n",
    "    ####################################################################################################\n",
    "    \n",
    "    #LIDC放射学家标注数据合集\n",
    "    samples = glob.glob(settings.BASE_DIR_SSD + \"LIDC_Annotations/cube/*.png\")\n",
    "    print(\"Samples Quantity: \", len(samples))\n",
    "    \n",
    "    random.shuffle(samples)\n",
    "      \n",
    "    #分割训练数据和测试数据\n",
    "    train_count = int((len(samples) * train_percentage) / 100)\n",
    "    samples_train = samples[:train_count]\n",
    "    samples_holdout = samples[train_count:]\n",
    "    \n",
    "    #如果需要训练所有数据，训练集则为全集\n",
    "    if full_luna_set:\n",
    "        samples_train += samples_holdout\n",
    "       \n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    print(\"Train Count:\",len(samples_train))\n",
    "\n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    #建立描述集合\n",
    "    train_res = []\n",
    "    holdout_res = []\n",
    "    sets = [(train_res, samples_train), (holdout_res, samples_holdout)]\n",
    "    \n",
    "    #对集合进行处理\n",
    "    for set_item in sets:\n",
    "  \n",
    "        res = set_item[0]\n",
    "        samples = set_item[1]\n",
    "          \n",
    "        for index, sample_path in enumerate(samples):    \n",
    "        \n",
    "            file_name = ntpath.basename(sample_path)\n",
    "\n",
    "            parts = file_name.split(\"_\")\n",
    "        \n",
    "            if True:\n",
    "                \n",
    "                subtlety_label = float(parts[-3])\n",
    "                lobulation_label = float(parts[-4])\n",
    "                internal_structure_label = float(parts[-5])\n",
    "                calcification_label = float(parts[-6])\n",
    "                texture_label = float(parts[-7])\n",
    "                spiculation_label = float(parts[-8])\n",
    "                margin_label = float(parts[-9])\n",
    "                sphericiy_label = float(parts[-10])\n",
    "                malignacy_label = float(parts[-11])\n",
    "                diameter_label = float(parts[-12])\n",
    "\n",
    "                res.append((sample_path, diameter_label, malignacy_label, sphericiy_label, margin_label, spiculation_label, texture_label, calcification_label, internal_structure_label, lobulation_label, subtlety_label))\n",
    "          \n",
    "    print(\"Train count: \", len(train_res), \", holdout count: \", len(holdout_res))\n",
    "   \n",
    "    return train_res, holdout_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
